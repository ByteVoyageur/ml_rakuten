# Projet Rakuten - Classification de Produits E-commerce

SystÃ¨me de classification automatique de produits Rakuten utilisant des techniques de Machine Learning sur texte et images.

## ğŸ“ Structure du Projet

```
rakuten/
â”œâ”€â”€ archive/
â”‚   â””â”€â”€ phase1_exploration_text/     # Code exploratoire archivÃ© (Phase 1)
â”œâ”€â”€ data/                            # Datasets Rakuten
â”‚   â”œâ”€â”€ X_train_update.csv
â”‚   â””â”€â”€ Y_train_CVw08PX.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 00_text_exploration.ipynb             # Exploration initiale
â”‚   â”œâ”€â”€ 01_Text_Preprocessing_Benchmark.ipynb # Phase 1: Preprocessing
â”‚   â”œâ”€â”€ 02_Vectorization_Strategies.ipynb     # Phase 2: Vectorization
â”‚   â”œâ”€â”€ 03_Model_Selection.ipynb              # Phase 2: Model Selection
â”‚   â””â”€â”€ archive/                              # Anciens notebooks
â”œâ”€â”€ src/
â”‚   â””â”€â”€ rakuten_text/               # BibliothÃ¨que modulaire de ML texte
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ preprocessing.py        # âœ… Nettoyage de texte (Phase 1)
â”‚       â”œâ”€â”€ benchmark.py            # âœ… Benchmark preprocessing (Phase 1)
â”‚       â”œâ”€â”€ features.py             # âœ… Features manuelles (Phase 2)
â”‚       â”œâ”€â”€ vectorization.py        # âœ… TF-IDF/Count + weighting (Phase 2)
â”‚       â”œâ”€â”€ experiments.py          # âœ… ExpÃ©rimentations systÃ©matiques (Phase 2)
â”‚       â”œâ”€â”€ models.py               # âœ… Pipelines ML (Phase 2)
â”‚       â”œâ”€â”€ categories.py           # âœ… Mapping 27 catÃ©gories (Phase 2)
â”‚       
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ configs/                    # Configurations optimales
â”‚   â””â”€â”€ models/                     # ModÃ¨les entraÃ®nÃ©s
â””â”€â”€ README.md                       # Ce fichier
```

## ğŸ¯ Objectif

Classifier automatiquement les produits Rakuten dans **27 catÃ©gories** en utilisant :
- **Texte** : DÃ©signation + Description des produits
- **Images** : Photos des produits (phase en cours)

## ğŸ“Š Ã‰tat d'Avancement

### âœ… Phase 1 : PrÃ©traitement de Texte (TERMINÃ‰E)

**RÃ©sultats clÃ©s :**
- **Baseline raw** : F1 = 0.7919
- **Meilleure stratÃ©gie** : `final_text_cleaner()` â†’ **F1 = 0.8024** (+1.32%)
- **22 stratÃ©gies** de nettoyage comparÃ©es sur 84,916 Ã©chantillons

**Fonction de production :** `final_text_cleaner()` dans `src/rakuten_text/preprocessing.py`

**Notebook :** `notebooks/01_Text_Preprocessing_Benchmark.ipynb`

### âœ… Phase 2 : Vectorization & ModÃ¨les Texte (TERMINÃ‰E)

**RÃ©sultats clÃ©s :**
- **Configuration optimale** : TF-IDF Split + features manuelles + title weighting
- **Performance** : F1 = 0.8420 (+6.33% vs baseline)
- **HyperparamÃ¨tres** : max_features=20k, ngram_range=(1,2), split_size=0.15

**ExpÃ©rimentations rÃ©alisÃ©es :**
1. Count vs TF-IDF vectorization
2. Split vs Merged text strategies
3. Manual features extraction (24 features)
4. **Title weighting** (1x-3x importance)
5. Hyperparameter grid search
6. Model comparison (LogReg, SVM, XGBoost, RF)

**Modules crÃ©Ã©s :**
- `vectorization.py` : TF-IDF/Count + FeatureWeighter (title weighting)
- `features.py` : 24 features manuelles textuelles
- `experiments.py` : Framework complet d'expÃ©rimentation + tracking + reporting
- `models.py` : Pipelines ML (LogReg, SVM, XGBoost, RF)
- `categories.py` : Mapping 27 catÃ©gories + noms courts

**FonctionnalitÃ©s clÃ©s :**
- âœ… Title weighting automatique (1x-3x)
- âœ… Tracking global des scores (tous les modÃ¨les)
- âœ… VÃ©rification d'optimalitÃ© automatique
- âœ… GÃ©nÃ©ration de rapports formatÃ©s

**Notebooks :**
- `02_Vectorization_Strategies.ipynb`
- `03_Model_Selection.ipynb`

### ğŸ”„ Phase 3 : Traitement d'Images (EN COURS)

Exploration des features visuelles et architectures CNN/Transfer Learning.

### ğŸ“‹ Phase 4 : Fusion Multimodale (PLANIFIÃ‰E)

- Ensembles multi-modaux (texte + image)
- Fine-tuning de modÃ¨les transformer
- Optimisation hyperparamÃ¨tres

## ğŸš€ DÃ©marrage Rapide

### Installation

```bash
# Cloner le repo
git clone <url>
cd rakuten

# Installer les dÃ©pendances
pip install -r requirements.txt

# TÃ©lÃ©charger les donnÃ©es NLTK (pour les stopwords)
python -c "import nltk; nltk.download('stopwords')"
```

### Utilisation de la BibliothÃ¨que de Texte

```python
from src.rakuten_text.preprocessing import final_text_cleaner

# Nettoyer un texte produit
text = "<p>Ordinateur <strong>portable</strong> HP 15.6 pouces - 299,99&nbsp;â‚¬</p>"
cleaned = final_text_cleaner(text)
print(cleaned)
# Output: "ordinateur portable hp 15.6 pouces 299,99 â‚¬"
```

### ExÃ©cuter le Benchmark

```python
from src.rakuten_text.benchmark import load_dataset, run_benchmark, analyze_results

# Charger les donnÃ©es
df = load_dataset(data_dir="data")

# ExÃ©cuter le benchmark
results_df = run_benchmark(df, verbose=True)

# Analyser les rÃ©sultats
analyze_results(results_df, top_n=10)
```

**Note :** Voir le notebook `notebooks/01_Text_Preprocessing_Benchmark.ipynb` pour un exemple complet.

## ğŸ“š Documentation

### Modules Principaux

#### `src/rakuten_text/preprocessing.py`
- `clean_text()` : Fonction modulaire avec options configurables (pour expÃ©rimentations)
- `final_text_cleaner()` : Pipeline optimisÃ© pour production (configuration gagnante)
- `get_available_options()` : Liste toutes les options de nettoyage disponibles

#### `src/rakuten_text/benchmark.py`
- `load_dataset()` : Charge les donnÃ©es Rakuten
- `define_experiments()` : DÃ©finit les configurations d'expÃ©riences
- `run_benchmark()` : ExÃ©cute le benchmark complet
- `analyze_results()` : Analyse et visualise les rÃ©sultats
- `save_results()` : Sauvegarde les rÃ©sultats en CSV

## ğŸ§ª Tests et ExpÃ©rimentations

Pour tester diffÃ©rentes stratÃ©gies de prÃ©traitement :

```python
from src.rakuten_text.preprocessing import clean_text

# Tester une configuration custom
text = "Votre texte ici"
cleaned = clean_text(
    text,
    fix_encoding=True,
    remove_html_tags=True,
    lowercase=True,
    remove_stopwords=True
)
```

## ğŸ“ˆ RÃ©sultats de Benchmark

| StratÃ©gie | F1 Score | AmÃ©lioration vs Baseline |
|-----------|----------|-------------------------|
| baseline_raw | 0.7921 | - |
| traditional_cleaning | **0.8024** | **+1.32%** |
| conservative_cleaning | 0.7985 | +0.81% |
| all_encoding_fixes | 0.7931 | +0.13% |

**DÃ©tails complets :** Voir `results/benchmark_results.csv` ou le notebook de dÃ©monstration.

## ğŸ—‚ï¸ Archives

Les fichiers exploratoires de la Phase 1 sont archivÃ©s dans `archive/phase1_exploration_text/` :
- Notebooks d'exploration
- Scripts de tests
- Anciennes versions de code

## ğŸ‘¥ Contributeurs

- **Xiaosong** : DÃ©veloppement et expÃ©rimentations

## ğŸ“ Notes Importantes

- **Langue** : Tous les commentaires et docstrings dans `src/` sont en **franÃ§ais** pour faciliter la collaboration
- **ReproductibilitÃ©** : Tous les benchmarks utilisent `random_state=42` pour garantir la reproductibilitÃ©
- **Performance** : Le pipeline de production est optimisÃ© pour le e-commerce franÃ§ais (mots vides FR + EN)

## ğŸ“„ Licence

Ce projet est destinÃ© Ã  des fins Ã©ducatives et de recherche.

---

**DerniÃ¨re mise Ã  jour** : 2025-12-08
**Version** : 2.0 (Phase 2 terminÃ©e - Text ML Pipeline complet)
