{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab0cbf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3f5de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapter le chemin vers le fichier CSV nettoyé produit par le notebook 01_xiaosong_text_clean.ipynb\n",
    "df = pd.read_csv(\"rakuten_text_train_v1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b44cc519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_str(x):\n",
    "    if isinstance(x, str):\n",
    "        return x\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return str(x)\n",
    "\n",
    "# Normalisation des deux colonnes texte principales\n",
    "df[\"designation_cleaned\"] = df[\"designation_cleaned\"].fillna(\"\").apply(safe_str)\n",
    "df[\"description_cleaned\"] = df[\"description_cleaned\"].fillna(\"\").apply(safe_str)\n",
    "\n",
    "# Colonne texte fusionnée (titre + description) pour la variante \"texte concaténé\"\n",
    "df[\"text_all\"] = (df[\"designation_cleaned\"] + \" \" + df[\"description_cleaned\"]).str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da8ae560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation_cleaned_len_char</th>\n",
       "      <th>designation_cleaned_len_tokens</th>\n",
       "      <th>description_cleaned_len_char</th>\n",
       "      <th>description_cleaned_len_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>546</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   designation_cleaned_len_char  designation_cleaned_len_tokens  \\\n",
       "0                            80                              10   \n",
       "1                           161                              24   \n",
       "2                            72                              10   \n",
       "3                            57                               7   \n",
       "4                            13                               2   \n",
       "\n",
       "   description_cleaned_len_char  description_cleaned_len_tokens  \n",
       "0                             0                               0  \n",
       "1                             0                               0  \n",
       "2                           546                              70  \n",
       "3                             0                               0  \n",
       "4                           127                              18  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features structurales sur le texte\n",
    "\n",
    "UNIT_PATTERN = re.compile(r\"\\b\\d+\\s*(cm|mm|kg|g|ml|l|m)\\b\", flags=re.IGNORECASE)\n",
    "MULT_PATTERN = re.compile(r\"\\bx\\s*\\d+\\b|\\b\\d+\\s*x\\b\", flags=re.IGNORECASE)\n",
    "DIGIT_PATTERN = re.compile(r\"\\d\")\n",
    "\n",
    "def structural_stats(s: str) -> dict:\n",
    "    \"\"\"Calcule des indicateurs simples de structure.\"\"\"\n",
    "    s = safe_str(s)\n",
    "    tokens = s.split()\n",
    "    length_char = len(s)\n",
    "    length_tokens = len(tokens)\n",
    "    \n",
    "    num_digits = len(DIGIT_PATTERN.findall(s))\n",
    "    num_units = len(UNIT_PATTERN.findall(s))\n",
    "    num_mult = len(MULT_PATTERN.findall(s))\n",
    "    \n",
    "    return {\n",
    "        \"len_char\": length_char,\n",
    "        \"len_tokens\": length_tokens,\n",
    "        \"num_digits\": num_digits,\n",
    "        \"num_units\": num_units,\n",
    "        \"num_mult_pattern\": num_mult,\n",
    "    }\n",
    "\n",
    "# Application sur le titre et la description\n",
    "for col in [\"designation_cleaned\", \"description_cleaned\"]:\n",
    "    stats_series = df[col].apply(structural_stats)\n",
    "    stats_df = pd.DataFrame(list(stats_series))\n",
    "    for c in stats_df.columns:\n",
    "        df[f\"{col}_{c}\"] = stats_df[c]\n",
    "\n",
    "# Aperçu de quelques features de longueur\n",
    "df[\n",
    "    [\n",
    "        \"designation_cleaned_len_char\",\n",
    "        \"designation_cleaned_len_tokens\",\n",
    "        \"description_cleaned_len_char\",\n",
    "        \"description_cleaned_len_tokens\",\n",
    "    ]\n",
    "].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2c6e316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF titre - forme : (84916, 20000)\n",
      "TF-IDF description - forme : (84916, 30000)\n",
      "TF-IDF texte fusionné - forme : (84916, 40000)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF pour le titre (designation)\n",
    "tfidf_title = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=5,\n",
    "    max_df=0.8,\n",
    "    lowercase=False,\n",
    "    tokenizer=str.split,\n",
    ")\n",
    "\n",
    "X_tfidf_title = tfidf_title.fit_transform(df[\"designation_cleaned\"])\n",
    "print(\"TF-IDF titre - forme :\", X_tfidf_title.shape)\n",
    "\n",
    "# TF-IDF pour la description\n",
    "tfidf_desc = TfidfVectorizer(\n",
    "    max_features=30000,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=5,\n",
    "    max_df=0.8,\n",
    "    lowercase=False,\n",
    "    tokenizer=str.split,\n",
    ")\n",
    "\n",
    "X_tfidf_desc = tfidf_desc.fit_transform(df[\"description_cleaned\"])\n",
    "print(\"TF-IDF description - forme :\", X_tfidf_desc.shape)\n",
    "\n",
    "# TF-IDF sur le texte fusionné (titre + description)\n",
    "tfidf_all = TfidfVectorizer(\n",
    "    max_features=40000,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=5,\n",
    "    max_df=0.8,\n",
    "    lowercase=False,\n",
    "    tokenizer=str.split,\n",
    ")\n",
    "\n",
    "X_tfidf_all = tfidf_all.fit_transform(df[\"text_all\"])\n",
    "print(\"TF-IDF texte fusionné - forme :\", X_tfidf_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "256edda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de colonnes numériques (features structurales) : 10\n",
      "Pipeline (texte séparé) : Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(transformer_weights={'num': 1.0,\n",
      "                                                        'tfidf_desc': 1.0,\n",
      "                                                        'tfidf_title': 2.0},\n",
      "                                   transformers=[('tfidf_title',\n",
      "                                                  TfidfVectorizer(lowercase=False,\n",
      "                                                                  max_df=0.8,\n",
      "                                                                  max_features=20000,\n",
      "                                                                  min_df=5,\n",
      "                                                                  ngram_range=(1,\n",
      "                                                                               3),\n",
      "                                                                  tokenizer=<method 'split' of 'str' objects>),\n",
      "                                                  'designation_cleaned'),\n",
      "                                                 ('tfidf_desc',\n",
      "                                                  TfidfVectorizer(lowercase=False,\n",
      "                                                                  max_df=...\n",
      "                                                   'designation_cleaned_num_digits',\n",
      "                                                   'designation_cleaned_num_units',\n",
      "                                                   'designation_cleaned_num_mult_pattern',\n",
      "                                                   'description_cleaned_len_char',\n",
      "                                                   'description_cleaned_len_tokens',\n",
      "                                                   'description_cleaned_num_digits',\n",
      "                                                   'description_cleaned_num_units',\n",
      "                                                   'description_cleaned_num_mult_pattern'])])),\n",
      "                ('model',\n",
      "                 LogisticRegression(C=2.0, class_weight='balanced',\n",
      "                                    max_iter=1000, n_jobs=-1, solver='saga'))])\n",
      "Pipeline (texte fusionné) : Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(transformers=[('tfidf_all',\n",
      "                                                  TfidfVectorizer(lowercase=False,\n",
      "                                                                  max_df=0.8,\n",
      "                                                                  max_features=40000,\n",
      "                                                                  min_df=5,\n",
      "                                                                  ngram_range=(1,\n",
      "                                                                               3),\n",
      "                                                                  tokenizer=<method 'split' of 'str' objects>),\n",
      "                                                  'text_all'),\n",
      "                                                 ('num',\n",
      "                                                  StandardScaler(with_mean=False),\n",
      "                                                  ['designation_cleaned_len_char',\n",
      "                                                   'designation_cleaned_len_tokens',\n",
      "                                                   'designation_cleaned_num_digits',\n",
      "                                                   'designation_cleaned_num_units',\n",
      "                                                   'designation_cleaned_num_mult_pattern',\n",
      "                                                   'description_cleaned_len_char',\n",
      "                                                   'description_cleaned_len_tokens',\n",
      "                                                   'description_cleaned_num_digits',\n",
      "                                                   'description_cleaned_num_units',\n",
      "                                                   'description_cleaned_num_mult_pattern'])])),\n",
      "                ('model',\n",
      "                 LogisticRegression(C=2.0, class_weight='balanced',\n",
      "                                    max_iter=1000, n_jobs=-1, solver='saga'))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Standardisation des features numériques\n",
    "num_scaler = StandardScaler(with_mean=False)  # with_mean=False pour matrices creuses\n",
    "\n",
    "# Colonnes numériques dérivées des stats structurales\n",
    "meta_cols = [\n",
    "    c for c in df.columns\n",
    "    if c.startswith(\"designation_cleaned_\")\n",
    "    or c.startswith(\"description_cleaned_\")\n",
    "]\n",
    "\n",
    "print(\"Nombre de colonnes numériques (features structurales) :\", len(meta_cols))\n",
    "\n",
    "# ==============================\n",
    "# 1) Préprocesseur A : titre / description séparés\n",
    "#    (on pourra jouer sur les poids des deux blocs TF-IDF)\n",
    "# ==============================\n",
    "preprocess_split = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tfidf_title\", tfidf_title, \"designation_cleaned\"),\n",
    "        (\"tfidf_desc\", tfidf_desc, \"description_cleaned\"),\n",
    "        (\"num\", num_scaler, meta_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "# Exemple de pondération manuelle : on donne plus de poids au titre\n",
    "preprocess_split.set_params(\n",
    "    transformer_weights={\n",
    "        \"tfidf_title\": 2.0,   # poids du bloc TF-IDF du titre\n",
    "        \"tfidf_desc\": 1.0,   # poids du bloc TF-IDF de la description\n",
    "        \"num\": 1.0,          # poids des features numériques\n",
    "    }\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# 2) Préprocesseur B : texte fusionné (titre + description)\n",
    "# ==============================\n",
    "preprocess_merged = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tfidf_all\", tfidf_all, \"text_all\"),\n",
    "        (\"num\", num_scaler, meta_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "# Modèle de base (le même pour les deux pipelines)\n",
    "log_reg = LogisticRegression(\n",
    "    C=2.0,\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"saga\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Pipeline A : texte séparé (titre / description)\n",
    "clf_split = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess_split),\n",
    "        (\"model\", log_reg),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline B : texte fusionné\n",
    "clf_merged = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess_merged),\n",
    "        (\"model\", log_reg),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Pipeline (texte séparé) :\", clf_split)\n",
    "print(\"Pipeline (texte fusionné) :\", clf_merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42d778e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille X_train : (67932, 13)\n",
      "Taille X_valid : (16984, 13)\n",
      "\n",
      "Entraînement du modèle A (titre / description séparés, pondérés)...\n",
      "\n",
      "[Modèle A] Weighted F1 (validation) : 0.8067\n",
      "\n",
      "[Modèle A] Classification report :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          10       0.42      0.66      0.51       623\n",
      "          40       0.75      0.65      0.69       502\n",
      "          50       0.79      0.82      0.80       336\n",
      "          60       0.85      0.83      0.84       166\n",
      "        1140       0.76      0.81      0.78       534\n",
      "        1160       0.91      0.92      0.92       791\n",
      "        1180       0.57      0.67      0.61       153\n",
      "        1280       0.76      0.56      0.64       974\n",
      "        1281       0.60      0.59      0.60       414\n",
      "        1300       0.86      0.90      0.88      1009\n",
      "        1301       0.91      0.96      0.93       161\n",
      "        1302       0.77      0.79      0.78       498\n",
      "        1320       0.80      0.76      0.78       648\n",
      "        1560       0.86      0.79      0.82      1015\n",
      "        1920       0.90      0.90      0.90       861\n",
      "        1940       0.73      0.94      0.82       161\n",
      "        2060       0.80      0.78      0.79       999\n",
      "        2220       0.76      0.84      0.80       165\n",
      "        2280       0.84      0.83      0.83       952\n",
      "        2403       0.78      0.73      0.75       955\n",
      "        2462       0.76      0.83      0.79       284\n",
      "        2522       0.92      0.90      0.91       998\n",
      "        2582       0.70      0.75      0.73       518\n",
      "        2583       0.98      0.92      0.95      2042\n",
      "        2585       0.75      0.82      0.78       499\n",
      "        2705       0.73      0.72      0.72       552\n",
      "        2905       0.99      0.99      0.99       174\n",
      "\n",
      "    accuracy                           0.80     16984\n",
      "   macro avg       0.79      0.80      0.79     16984\n",
      "weighted avg       0.81      0.80      0.81     16984\n",
      "\n",
      "\n",
      "Entraînement du modèle B (texte fusionné)...\n",
      "\n",
      "[Modèle B] Weighted F1 (validation) : 0.7526\n",
      "\n",
      "[Modèle B] Classification report :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          10       0.32      0.70      0.44       623\n",
      "          40       0.76      0.52      0.62       502\n",
      "          50       0.74      0.77      0.75       336\n",
      "          60       0.88      0.77      0.82       166\n",
      "        1140       0.69      0.78      0.73       534\n",
      "        1160       0.84      0.89      0.86       791\n",
      "        1180       0.53      0.55      0.54       153\n",
      "        1280       0.74      0.46      0.57       974\n",
      "        1281       0.55      0.54      0.54       414\n",
      "        1300       0.81      0.86      0.83      1009\n",
      "        1301       0.89      0.94      0.91       161\n",
      "        1302       0.70      0.68      0.69       498\n",
      "        1320       0.75      0.63      0.69       648\n",
      "        1560       0.79      0.73      0.76      1015\n",
      "        1920       0.88      0.86      0.87       861\n",
      "        1940       0.66      0.93      0.77       161\n",
      "        2060       0.73      0.72      0.73       999\n",
      "        2220       0.69      0.81      0.74       165\n",
      "        2280       0.83      0.80      0.81       952\n",
      "        2403       0.70      0.67      0.69       955\n",
      "        2462       0.69      0.79      0.73       284\n",
      "        2522       0.91      0.82      0.86       998\n",
      "        2582       0.63      0.71      0.67       518\n",
      "        2583       0.98      0.86      0.92      2042\n",
      "        2585       0.66      0.72      0.69       499\n",
      "        2705       0.69      0.68      0.68       552\n",
      "        2905       0.87      0.97      0.92       174\n",
      "\n",
      "    accuracy                           0.75     16984\n",
      "   macro avg       0.74      0.75      0.74     16984\n",
      "weighted avg       0.77      0.75      0.75     16984\n",
      "\n",
      "\n",
      "Résumé des scores (validation) :\n",
      " - Modèle A (séparé)  : 0.8067\n",
      " - Modèle B (fusionné) : 0.7526\n",
      " - Différence (A - B)  : 0.0541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# Construction de X avec toutes les colonnes utiles\n",
    "X = df[[\"designation_cleaned\", \"description_cleaned\", \"text_all\"] + meta_cols]\n",
    "y = df[\"prdtypecode\"].values\n",
    "\n",
    "# Split entraînement / validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "print(\"Taille X_train :\", X_train.shape)\n",
    "print(\"Taille X_valid :\", X_valid.shape)\n",
    "\n",
    "# =========================\n",
    "# 1) Modèle A : texte séparé\n",
    "# =========================\n",
    "print(\"\\nEntraînement du modèle A (titre / description séparés, pondérés)...\")\n",
    "clf_split.fit(X_train, y_train)\n",
    "\n",
    "y_pred_split = clf_split.predict(X_valid)\n",
    "f1_split = f1_score(y_valid, y_pred_split, average=\"weighted\")\n",
    "\n",
    "print(f\"\\n[Modèle A] Weighted F1 (validation) : {f1_split:.4f}\\n\")\n",
    "print(\"[Modèle A] Classification report :\\n\")\n",
    "print(classification_report(y_valid, y_pred_split))\n",
    "\n",
    "# =========================\n",
    "# 2) Modèle B : texte fusionné\n",
    "# =========================\n",
    "print(\"\\nEntraînement du modèle B (texte fusionné)...\")\n",
    "clf_merged.fit(X_train, y_train)\n",
    "\n",
    "y_pred_merged = clf_merged.predict(X_valid)\n",
    "f1_merged = f1_score(y_valid, y_pred_merged, average=\"weighted\")\n",
    "\n",
    "print(f\"\\n[Modèle B] Weighted F1 (validation) : {f1_merged:.4f}\\n\")\n",
    "print(\"[Modèle B] Classification report :\\n\")\n",
    "print(classification_report(y_valid, y_pred_merged))\n",
    "\n",
    "# Comparaison simple des scores\n",
    "print(\"\\nRésumé des scores (validation) :\")\n",
    "print(f\" - Modèle A (séparé)  : {f1_split:.4f}\")\n",
    "print(f\" - Modèle B (fusionné) : {f1_merged:.4f}\")\n",
    "print(f\" - Différence (A - B)  : {f1_split - f1_merged:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35e86a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Pondérations : titre=1.0, description=1.0\n",
      "==================================================\n",
      "Weighted F1 (validation) : 0.7723\n",
      "\n",
      "==================================================\n",
      "Pondérations : titre=2.0, description=1.0\n",
      "==================================================\n",
      "Weighted F1 (validation) : 0.8067\n",
      "\n",
      "==================================================\n",
      "Pondérations : titre=3.0, description=1.0\n",
      "==================================================\n",
      "Weighted F1 (validation) : 0.8159\n",
      "\n",
      "==================================================\n",
      "Pondérations : titre=1.0, description=2.0\n",
      "==================================================\n",
      "Weighted F1 (validation) : 0.7808\n",
      "\n",
      "Résumé pondérations / scores :\n",
      " - (titre=1.0, description=1.0) -> F1=0.7723\n",
      " - (titre=2.0, description=1.0) -> F1=0.8067\n",
      " - (titre=3.0, description=1.0) -> F1=0.8159\n",
      " - (titre=1.0, description=2.0) -> F1=0.7808\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Liste de pondérations à tester pour (titre, description)\n",
    "weight_grid = [\n",
    "    (1.0, 1.0),\n",
    "    (2.0, 1.0),\n",
    "    (3.0, 1.0),\n",
    "    (1.0, 2.0),\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for w_title, w_desc in weight_grid:\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"Pondérations : titre={w_title}, description={w_desc}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Copie du préprocesseur pour ne pas écraser l'original\n",
    "    preprocess_w = deepcopy(preprocess_split)\n",
    "    preprocess_w.set_params(\n",
    "        transformer_weights={\n",
    "            \"tfidf_title\": w_title,\n",
    "            \"tfidf_desc\": w_desc,\n",
    "            \"num\": 1.0,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    clf_w = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocess\", preprocess_w),\n",
    "            (\"model\", log_reg),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    clf_w.fit(X_train, y_train)\n",
    "    y_pred_w = clf_w.predict(X_valid)\n",
    "    f1_w = f1_score(y_valid, y_pred_w, average=\"weighted\")\n",
    "    \n",
    "    print(f\"Weighted F1 (validation) : {f1_w:.4f}\")\n",
    "    results.append((w_title, w_desc, f1_w))\n",
    "\n",
    "print(\"\\nRésumé pondérations / scores :\")\n",
    "for w_title, w_desc, f1_w in results:\n",
    "    print(f\" - (titre={w_title}, description={w_desc}) -> F1={f1_w:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "099e93b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#     \"model__C\": [0.5, 1.0, 2.0],\n",
    "#     \"preprocess__title_tfidf__max_features\": [10000, 20000],\n",
    "#     \"preprocess__desc_tfidf__max_features\": [20000, 30000],\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(\n",
    "#     estimator=clf_pipeline,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring=\"f1_weighted\",\n",
    "#     cv=3,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2,\n",
    "# )\n",
    "\n",
    "# print(\"Lancement de la GridSearch (peut être un peu long)...\")\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"\\nMeilleurs paramètres trouvés :\", grid.best_params_)\n",
    "# print(\"Meilleur score (F1 pondéré, CV) :\", grid.best_score_)\n",
    "\n",
    "# # Évaluation du meilleur modèle sur le jeu de validation\n",
    "# best_model = grid.best_estimator_\n",
    "# y_pred_best = best_model.predict(X_valid)\n",
    "# best_f1 = f1_score(y_valid, y_pred_best, average=\"weighted\")\n",
    "\n",
    "# print(f\"\\nWeighted F1 du meilleur modèle sur validation : {best_f1:.4f}\\n\")\n",
    "# print(\"Classification report du meilleur modèle :\\n\")\n",
    "# print(classification_report(y_valid, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb60bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
