{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Results Analysis & Visualization\n",
    "\n",
    "**Purpose:** Analyze and visualize results from `src/run_training.py`\n",
    "\n",
    "This notebook loads saved training artifacts and provides comprehensive analysis:\n",
    "- Training curves (loss, accuracy, learning rate)\n",
    "- Model performance metrics\n",
    "- Class-wise performance analysis\n",
    "- Confusion matrix\n",
    "- Misclassification analysis\n",
    "\n",
    "**Input Files:**\n",
    "- `checkpoints/resnet50_full/training_history.csv`\n",
    "- `checkpoints/resnet50_full/best_model.pth`\n",
    "- `checkpoints/resnet50_full/training_metadata.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint directory to analyze\n",
    "CHECKPOINT_DIR = '../../checkpoints/resnet50_full'\n",
    "\n",
    "# File paths\n",
    "HISTORY_PATH = Path(CHECKPOINT_DIR) / 'training_history.csv'\n",
    "METADATA_PATH = Path(CHECKPOINT_DIR) / 'training_metadata.json'\n",
    "MODEL_PATH = Path(CHECKPOINT_DIR) / 'best_model.pth'\n",
    "\n",
    "# Output directory for figures\n",
    "OUTPUT_DIR = Path(CHECKPOINT_DIR) / 'analysis'\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Checkpoint directory: {CHECKPOINT_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Training Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training history\n",
    "print(\"Loading training history...\")\n",
    "history_df = pd.read_csv(HISTORY_PATH)\n",
    "print(f\"  ✓ Loaded {len(history_df)} epochs\")\n",
    "\n",
    "# Load metadata\n",
    "print(\"\\nLoading training metadata...\")\n",
    "with open(METADATA_PATH, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "print(f\"  ✓ Model: {metadata['model']}\")\n",
    "print(f\"  ✓ Classes: {metadata['num_classes']}\")\n",
    "print(f\"  ✓ Epochs trained: {metadata['training_config']['epochs']}\")\n",
    "print(f\"  ✓ Batch size: {metadata['training_config']['batch_size']}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nTraining history preview:\")\n",
    "history_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best epoch\n",
    "best_epoch = history_df['val_loss'].idxmin()\n",
    "best_val_loss = history_df.loc[best_epoch, 'val_loss']\n",
    "best_val_acc = history_df.loc[best_epoch, 'val_acc']\n",
    "\n",
    "# Final epoch results\n",
    "final_train_loss = history_df['train_loss'].iloc[-1]\n",
    "final_train_acc = history_df['train_acc'].iloc[-1]\n",
    "final_val_loss = history_df['val_loss'].iloc[-1]\n",
    "final_val_acc = history_df['val_acc'].iloc[-1]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nBest Results (Epoch {best_epoch + 1}):\")\n",
    "print(f\"  Val Loss: {best_val_loss:.4f}\")\n",
    "print(f\"  Val Accuracy: {best_val_acc:.2f}%\")\n",
    "\n",
    "print(f\"\\nFinal Results (Epoch {len(history_df)}):\")\n",
    "print(f\"  Train Loss: {final_train_loss:.4f}\")\n",
    "print(f\"  Train Accuracy: {final_train_acc:.2f}%\")\n",
    "print(f\"  Val Loss: {final_val_loss:.4f}\")\n",
    "print(f\"  Val Accuracy: {final_val_acc:.2f}%\")\n",
    "\n",
    "# Improvement metrics\n",
    "train_acc_improvement = final_train_acc - history_df['train_acc'].iloc[0]\n",
    "val_acc_improvement = final_val_acc - history_df['val_acc'].iloc[0]\n",
    "\n",
    "print(f\"\\nImprovement from Epoch 1:\")\n",
    "print(f\"  Train Accuracy: +{train_acc_improvement:.2f}%\")\n",
    "print(f\"  Val Accuracy: +{val_acc_improvement:.2f}%\")\n",
    "\n",
    "# Overfitting check\n",
    "train_val_gap = final_train_acc - final_val_acc\n",
    "print(f\"\\nOverfitting Analysis:\")\n",
    "print(f\"  Train-Val Gap: {train_val_gap:.2f}%\")\n",
    "if train_val_gap < 5:\n",
    "    print(\"  Status: ✅ No significant overfitting\")\n",
    "elif train_val_gap < 10:\n",
    "    print(\"  Status: ⚠️ Slight overfitting\")\n",
    "else:\n",
    "    print(\"  Status: ❌ Significant overfitting - consider regularization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Curves Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Loss curves\n",
    "ax = axes[0, 0]\n",
    "ax.plot(history_df.index + 1, history_df['train_loss'], \n",
    "        label='Train Loss', marker='o', linewidth=2, markersize=6)\n",
    "ax.plot(history_df.index + 1, history_df['val_loss'], \n",
    "        label='Val Loss', marker='s', linewidth=2, markersize=6)\n",
    "ax.axvline(best_epoch + 1, color='red', linestyle='--', alpha=0.5, label=f'Best Epoch ({best_epoch + 1})')\n",
    "ax.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Accuracy curves\n",
    "ax = axes[0, 1]\n",
    "ax.plot(history_df.index + 1, history_df['train_acc'], \n",
    "        label='Train Acc', marker='o', linewidth=2, markersize=6)\n",
    "ax.plot(history_df.index + 1, history_df['val_acc'], \n",
    "        label='Val Acc', marker='s', linewidth=2, markersize=6)\n",
    "ax.axvline(best_epoch + 1, color='red', linestyle='--', alpha=0.5, label=f'Best Epoch ({best_epoch + 1})')\n",
    "ax.axhline(60, color='green', linestyle=':', alpha=0.5, label='Target (60%)')\n",
    "ax.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Learning rate schedule\n",
    "ax = axes[1, 0]\n",
    "ax.plot(history_df.index + 1, history_df['learning_rates'], \n",
    "        marker='o', linewidth=2, markersize=6, color='green')\n",
    "ax.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Learning Rate', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Train-Val Gap\n",
    "ax = axes[1, 1]\n",
    "train_val_gap = history_df['train_acc'] - history_df['val_acc']\n",
    "ax.plot(history_df.index + 1, train_val_gap, \n",
    "        marker='o', linewidth=2, markersize=6, color='orange')\n",
    "ax.axhline(0, color='black', linestyle='-', alpha=0.3)\n",
    "ax.axhline(5, color='yellow', linestyle='--', alpha=0.5, label='Slight overfitting')\n",
    "ax.axhline(10, color='red', linestyle='--', alpha=0.5, label='Significant overfitting')\n",
    "ax.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Train - Val Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Overfitting Analysis (Train-Val Gap)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Figure saved to {OUTPUT_DIR / 'training_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Epoch-by-Epoch Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detailed epoch statistics\n",
    "history_display = history_df.copy()\n",
    "history_display.index = history_display.index + 1\n",
    "history_display.index.name = 'Epoch'\n",
    "\n",
    "# Add improvement columns\n",
    "history_display['val_acc_delta'] = history_display['val_acc'].diff()\n",
    "history_display['val_loss_delta'] = history_display['val_loss'].diff()\n",
    "\n",
    "# Format for display\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "print(\"Epoch-by-Epoch Statistics:\")\n",
    "print(\"=\" * 100)\n",
    "history_display[['train_loss', 'train_acc', 'val_loss', 'val_acc', 'val_acc_delta', 'learning_rates']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation (Optional - Requires Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section can be expanded to:\n",
    "# 1. Load the best model\n",
    "# 2. Run inference on validation set\n",
    "# 3. Generate confusion matrix\n",
    "# 4. Analyze per-class performance\n",
    "# 5. Show misclassified examples\n",
    "\n",
    "print(\"Model evaluation section (to be implemented)\")\n",
    "print(f\"Model checkpoint available at: {MODEL_PATH}\")\n",
    "print(\"\\nTo add evaluation:\")\n",
    "print(\"1. Load validation data\")\n",
    "print(\"2. Load best_model.pth\")\n",
    "print(\"3. Run inference\")\n",
    "print(\"4. Generate confusion matrix and classification report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Based on results\n",
    "if best_val_acc >= 60:\n",
    "    print(\"\\n✅ Excellent results! Val accuracy >= 60%\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"  1. Fine-tune with unfrozen backbone:\")\n",
    "    print(\"     python src/run_training.py --no_freeze_backbone --lr 1e-5 --epochs 10\")\n",
    "    print(\"  2. Try ensemble methods\")\n",
    "    print(\"  3. Deploy to production\")\n",
    "elif best_val_acc >= 50:\n",
    "    print(\"\\n⚠️ Moderate results. Consider:\")\n",
    "    print(\"\\nRecommended actions:\")\n",
    "    print(\"  1. Train longer:\")\n",
    "    print(\"     python src/run_training.py --epochs 25\")\n",
    "    print(\"  2. Fine-tune backbone:\")\n",
    "    print(\"     python src/run_training.py --no_freeze_backbone --lr 1e-5\")\n",
    "    print(\"  3. Try different model:\")\n",
    "    print(\"     python src/run_training.py --model vit\")\n",
    "else:\n",
    "    print(\"\\n❌ Results below expectations. Investigate:\")\n",
    "    print(\"\\nPossible issues:\")\n",
    "    print(\"  1. Data quality - check images and labels\")\n",
    "    print(\"  2. Model architecture - try different models\")\n",
    "    print(\"  3. Hyperparameters - adjust learning rate, batch size\")\n",
    "    print(\"  4. Training duration - train for more epochs\")\n",
    "\n",
    "# Overfitting analysis\n",
    "if train_val_gap > 10:\n",
    "    print(\"\\n⚠️ Significant overfitting detected!\")\n",
    "    print(\"\\nTry:\")\n",
    "    print(\"  - Increase dropout rate\")\n",
    "    print(\"  - Add more data augmentation\")\n",
    "    print(\"  - Reduce model complexity\")\n",
    "    print(\"  - Add L2 regularization\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary report\n",
    "report = {\n",
    "    'training_info': {\n",
    "        'model': metadata['model'],\n",
    "        'num_classes': metadata['num_classes'],\n",
    "        'total_epochs': len(history_df),\n",
    "        'batch_size': metadata['training_config']['batch_size'],\n",
    "        'learning_rate': metadata['training_config']['learning_rate'],\n",
    "    },\n",
    "    'best_results': {\n",
    "        'epoch': int(best_epoch + 1),\n",
    "        'val_loss': float(best_val_loss),\n",
    "        'val_accuracy': float(best_val_acc),\n",
    "    },\n",
    "    'final_results': {\n",
    "        'train_loss': float(final_train_loss),\n",
    "        'train_accuracy': float(final_train_acc),\n",
    "        'val_loss': float(final_val_loss),\n",
    "        'val_accuracy': float(final_val_acc),\n",
    "    },\n",
    "    'metrics': {\n",
    "        'train_acc_improvement': float(train_acc_improvement),\n",
    "        'val_acc_improvement': float(val_acc_improvement),\n",
    "        'train_val_gap': float(train_val_gap),\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save report\n",
    "report_path = OUTPUT_DIR / 'training_summary.json'\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(f\"✓ Summary report saved to {report_path}\")\n",
    "print(\"\\nReport contents:\")\n",
    "print(json.dumps(report, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
