{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swin + DeBERTa Multimodal Fusion (FIXED VERSION)\n",
    "\n",
    "## ✅ Data Leakage Issues FIXED:\n",
    "- **Proper data split**: 85% dev (train+val) / 15% holdout (final test)\n",
    "- **LabelEncoder fitted ONLY on dev set**\n",
    "- **Holdout set used ONLY for final evaluation**\n",
    "- **WandB integration** for experiment tracking\n",
    "\n",
    "## Changes from Original:\n",
    "1. ❌ Old: Used all 84,916 samples (100%) → ✅ Fixed: 72,178 dev / 12,738 holdout\n",
    "2. ❌ Old: train/val split on full data → ✅ Fixed: 15% holdout reserved from start\n",
    "3. ❌ Old: No experiment tracking → ✅ Fixed: WandB integration\n",
    "4. ❌ Old: LabelEncoder on all data → ✅ Fixed: Fit only on dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Setup Environment & Dependencies\n",
    "!pip install -q transformers timm gdown pandas scikit-learn matplotlib wandb sentencepiece\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gdown\n",
    "import timm\n",
    "import wandb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "\n",
    "# Set seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Environment setup complete. Using device: {device}\")\n",
    "\n",
    "# Initialize WandB\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. Download Data with PROPER SPLIT\n",
    "def load_csv_from_gdrive(share_url: str, **read_csv_kwargs) -> pd.DataFrame:\n",
    "    try:\n",
    "        file_id = share_url.split(\"/d/\")[1].split(\"/\")[0]\n",
    "        download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "        return pd.read_csv(download_url, **read_csv_kwargs)\n",
    "    except IndexError:\n",
    "        print(f\"Error parsing URL: {share_url}\")\n",
    "        return None\n",
    "\n",
    "print(\"Downloading CSV data...\")\n",
    "X_train_url = \"https://drive.google.com/file/d/1geSiJTTjamysiSbJ8-W9gR1kv-x6HyEd/view?usp=drive_link\"\n",
    "y_train_url = \"https://drive.google.com/file/d/16czWmLR5Ff0s5aYIqy1rHT7hc6Gcpfw3/view?usp=sharing\"\n",
    "\n",
    "try:\n",
    "    X_train_full = load_csv_from_gdrive(X_train_url)\n",
    "    y_train_full = load_csv_from_gdrive(y_train_url)\n",
    "\n",
    "    if X_train_full is not None and y_train_full is not None:\n",
    "        print(f\"Total data loaded: {len(X_train_full):,} samples\")\n",
    "        \n",
    "        # ============================================================================\n",
    "        # ✅ FIX: PROPER DATA SPLIT (85% dev / 15% holdout)\n",
    "        # ============================================================================\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SPLITTING DATA (85% dev / 15% holdout)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        X_dev, X_holdout, y_dev, y_holdout = train_test_split(\n",
    "            X_train_full,\n",
    "            y_train_full['prdtypecode'],\n",
    "            test_size=0.15,\n",
    "            random_state=42,\n",
    "            stratify=y_train_full['prdtypecode']\n",
    "        )\n",
    "        \n",
    "        df_dev = X_dev.copy()\n",
    "        df_dev['prdtypecode'] = y_dev\n",
    "        \n",
    "        df_holdout = X_holdout.copy()\n",
    "        df_holdout['prdtypecode'] = y_holdout\n",
    "        \n",
    "        print(f\"✓ Development set: {len(df_dev):,} samples (85%)\")\n",
    "        print(f\"✓ Hold-out test set: {len(df_holdout):,} samples (15%)\")\n",
    "        print(f\"✓ Classes: {df_dev['prdtypecode'].nunique()}\")\n",
    "        print(\"\\n⚠️  CRITICAL: Holdout set will ONLY be used for final evaluation!\")\n",
    "        print(\"=\"*80)\n",
    "    else:\n",
    "        raise ValueError(\"Failed to load DataFrames\")\n",
    "except Exception as e:\n",
    "    print(f\"CSV download failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. Download Images\n",
    "IMAGE_FILE_ID = \"15ZkS0iTQ7j3mHpxil4mABlXwP-jAN_zi\"\n",
    "\n",
    "if not os.path.exists(\"/content/images\"):\n",
    "    print(\"\\nDownloading images...\")\n",
    "    os.makedirs(\"/content/tmp\", exist_ok=True)\n",
    "    os.makedirs(\"/content/images\", exist_ok=True)\n",
    "    !gdown --id $IMAGE_FILE_ID -O /content/tmp/images.zip\n",
    "\n",
    "    print(\"Unzipping images...\")\n",
    "    !unzip -q -o /content/tmp/images.zip -d /content/images\n",
    "    print(\"Images unzipped\")\n",
    "else:\n",
    "    print(\"\\nImages already exist, skipping download\")\n",
    "\n",
    "IMG_ROOT = \"/content/images/images/image_train\"\n",
    "print(f\"Image Root: {IMG_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4. Download Custom Model Weights\n",
    "print(\"\\nDownloading custom model weights...\")\n",
    "\n",
    "# Swin V2 Weights\n",
    "if not os.path.exists('swin_v2_best.pth'):\n",
    "    gdown.download(id='1MM87li5P6pWzCs-7uwlQb0msH8s8kZDf', output='swin_v2_best.pth', quiet=False)\n",
    "\n",
    "# DeBERTa V2 Weights\n",
    "if not os.path.exists('deberta_v2_best.pth'):\n",
    "    gdown.download(id='1wNsbubOYXJa611AaeCjkM4bHSstgpPy7', output='deberta_v2_best.pth', quiet=False)\n",
    "\n",
    "print(\"All files ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 5. Label Encoding (FIT ON DEV ONLY!)\n",
    "print(\"=\"*80)\n",
    "print(\"LABEL ENCODING (DEV SET ONLY)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ✅ FIX: Encode labels on DEV SET ONLY\n",
    "le = LabelEncoder()\n",
    "le.fit(df_dev['prdtypecode'])  # ✅ FIT ONLY ON DEV\n",
    "\n",
    "df_dev['encoded_label'] = le.transform(df_dev['prdtypecode'])\n",
    "df_holdout['encoded_label'] = le.transform(df_holdout['prdtypecode'])\n",
    "\n",
    "NUM_CLASSES = len(le.classes_)\n",
    "print(f\"✓ LabelEncoder fitted on dev set ONLY (no data leakage)\")\n",
    "print(f\"✓ Number of classes: {NUM_CLASSES}\")\n",
    "assert NUM_CLASSES == 27, f\"Expected 27 classes, got {NUM_CLASSES}\"\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 6. Text Preprocessing & Train/Val Split\n",
    "# Text Cleaning: Merge designation and description\n",
    "df_dev['text'] = df_dev['designation'].fillna('') + \" \" + df_dev['description'].fillna('')\n",
    "df_dev['text'] = df_dev['text'].astype(str).str.lower()\n",
    "\n",
    "df_holdout['text'] = df_holdout['designation'].fillna('') + \" \" + df_holdout['description'].fillna('')\n",
    "df_holdout['text'] = df_holdout['text'].astype(str).str.lower()\n",
    "\n",
    "# Split Dev into Train/Val\n",
    "print(\"=\"*80)\n",
    "print(\"SPLITTING DEV SET (85% train / 15% val)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df_dev,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=df_dev['encoded_label']\n",
    ")\n",
    "\n",
    "total_samples = len(df_dev) + len(df_holdout)\n",
    "print(f\"✓ Training:   {len(train_df):,} samples (~{len(train_df)/total_samples*100:.1f}%)\")\n",
    "print(f\"✓ Validation: {len(val_df):,} samples (~{len(val_df)/total_samples*100:.1f}%)\")\n",
    "print(f\"✓ Hold-out:   {len(df_holdout):,} samples (15.0%)\")\n",
    "print(\"\\n⚠️  Model selection will use Train/Val ONLY\")\n",
    "print(\"⚠️  Holdout will be evaluated at the END\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 7. Dataset Definition\n",
    "class RakutenMultiModalDataset(Dataset):\n",
    "    def __init__(self, df, img_root, tokenizer, transform=None, max_len=128):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_root = img_root\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # 1. Image Processing\n",
    "        img_name = f\"image_{row['imageid']}_product_{row['productid']}.jpg\"\n",
    "        img_path = os.path.join(self.img_root, img_name)\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except (FileNotFoundError, OSError):\n",
    "            # Fallback for missing/corrupt images\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # 2. Text Processing\n",
    "        text = str(row['text'])\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'pixel_values': image,\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(row['encoded_label'], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(f\"Dataset class ready. Training: {len(train_df):,}, Validation: {len(val_df):,}, Holdout: {len(df_holdout):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 8. Define Fusion Model\n",
    "class RakutenFusionModel(nn.Module):\n",
    "    def __init__(self, num_classes=27, text_model_name=\"microsoft/deberta-v3-base\", img_model_name=\"swin_base_patch4_window7_224\"):\n",
    "        super().__init__()\n",
    "\n",
    "        # --- Text Backbone (DeBERTa) ---\n",
    "        self.text_backbone = AutoModel.from_pretrained(text_model_name)\n",
    "        text_dim = self.text_backbone.config.hidden_size  # 768 for Base\n",
    "\n",
    "        # --- Image Backbone (Swin) ---\n",
    "        self.img_backbone = timm.create_model(img_model_name, pretrained=True, num_classes=0)\n",
    "        img_dim = self.img_backbone.num_features  # 1024 for Base\n",
    "\n",
    "        # --- Fusion Head ---\n",
    "        fusion_dim = text_dim + img_dim\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.BatchNorm1d(fusion_dim),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(fusion_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values, input_ids, attention_mask):\n",
    "        # Image Features\n",
    "        img_feats = self.img_backbone(pixel_values)  # [Batch, 1024]\n",
    "\n",
    "        # Text Features (CLS Token)\n",
    "        text_out = self.text_backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_feats = text_out.last_hidden_state[:, 0, :]  # [Batch, 768]\n",
    "\n",
    "        # Concatenate\n",
    "        features = torch.cat([img_feats, text_feats], dim=1)\n",
    "\n",
    "        # Classify\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "def smart_load_weights(model, swin_path, deberta_path):\n",
    "    \"\"\"Loads weights safely by filtering out mismatched layers.\"\"\"\n",
    "    print(\"Loading weights...\")\n",
    "\n",
    "    # 1. Load Swin Weights\n",
    "    try:\n",
    "        swin_state = torch.load(swin_path, map_location='cpu', weights_only=False)\n",
    "        if 'model_state_dict' in swin_state: \n",
    "            swin_state = swin_state['model_state_dict']\n",
    "        elif 'state_dict' in swin_state: \n",
    "            swin_state = swin_state['state_dict']\n",
    "\n",
    "        msg = model.img_backbone.load_state_dict(swin_state, strict=False)\n",
    "        print(f\" -> Swin weights loaded. Missing keys: {len(msg.missing_keys)}\")\n",
    "    except Exception as e:\n",
    "        print(f\" -> Error loading Swin weights: {e}\")\n",
    "\n",
    "    # 2. Load DeBERTa Weights\n",
    "    try:\n",
    "        text_state = torch.load(deberta_path, map_location='cpu', weights_only=False)\n",
    "        if 'model_state_dict' in text_state: \n",
    "            text_state = text_state['model_state_dict']\n",
    "\n",
    "        # Filter out classifier layers\n",
    "        new_state_dict = {k: v for k, v in text_state.items() if 'classifier' not in k and 'pooler' not in k}\n",
    "\n",
    "        msg = model.text_backbone.load_state_dict(new_state_dict, strict=False)\n",
    "        print(f\" -> DeBERTa weights loaded. Unexpected keys: {len(msg.unexpected_keys)}\")\n",
    "    except Exception as e:\n",
    "        print(f\" -> Error loading DeBERTa weights: {e}\")\n",
    "\n",
    "print(\"Model architecture defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 9. Initialize Model and Dataloaders\n",
    "BATCH_SIZE = 16\n",
    "LR = 2e-5\n",
    "EPOCHS = 5\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Tokenizer & Transforms\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Instantiate Datasets & Loaders\n",
    "train_ds = RakutenMultiModalDataset(train_df, IMG_ROOT, tokenizer, transform=transform_train)\n",
    "val_ds = RakutenMultiModalDataset(val_df, IMG_ROOT, tokenizer, transform=transform_val)\n",
    "holdout_ds = RakutenMultiModalDataset(df_holdout, IMG_ROOT, tokenizer, transform=transform_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "holdout_loader = DataLoader(holdout_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# Initialize Model\n",
    "model = RakutenFusionModel(num_classes=NUM_CLASSES)\n",
    "model.to(device)\n",
    "\n",
    "# Load Custom Weights\n",
    "smart_load_weights(model, 'swin_v2_best.pth', 'deberta_v2_best.pth')\n",
    "\n",
    "print(\"Model initialized and weights loaded.\")\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 10. Training with WandB\n",
    "\n",
    "# Detect execution environment\n",
    "import sys\n",
    "ENVIRONMENT = \"colab\" if 'google.colab' in sys.modules else \"local\"\n",
    "\n",
    "# Initialize WandB\n",
    "\n",
    "wandb.init(\n",
    "    project=\"rakuten-fusion\",\n",
    "    entity=\"xiaosong-dev-formation-data-science\",\n",
    "    name=f\"swin_deberta_fusion_v1_{datetime.now().strftime('%Y%m%d_%H%M')}\",\n",
    "    tags=[\"fusion\", \"swin\", \"v1\", \"production\", ENVIRONMENT],\n",
    "    config=CONFIG,\n",
    "    notes=\"Swin + DeBERTa multimodal fusion with proper data split\"\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=LR, steps_per_epoch=len(train_loader), epochs=EPOCHS\n",
    ")\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Validating\"):\n",
    "            pixel_values = batch['pixel_values'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(pixel_values, input_ids, mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    f1 = f1_score(targets, preds, average='weighted')\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    return val_loss / len(loader), f1, acc\n",
    "\n",
    "# Training Loop\n",
    "print(\"=\"*80)\n",
    "print(f\"TRAINING MULTIMODAL FUSION ({EPOCHS} epochs)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_f1 = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for batch in pbar:\n",
    "        pixel_values = batch['pixel_values'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(pixel_values, input_ids, mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    # Validation\n",
    "    val_loss, val_f1, val_acc = evaluate(model, val_loader)\n",
    "    \n",
    "    # Log to WandB\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss / len(train_loader),\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_f1\": val_f1,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "    })\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Loss={train_loss/len(train_loader):.4f}, Val F1={val_f1:.4f}, Val Acc={val_acc:.4f}\")\n",
    "\n",
    "    # Save Best Model\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), \"fusion_model_best_FIXED.pth\")\n",
    "        print(\"  ✅ New Best Model Saved!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Training Complete. Best Val F1: {best_f1:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 11. FINAL EVALUATION ON HOLDOUT TEST SET\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL EVALUATION ON HOLDOUT TEST SET\")\n",
    "print(\"=\"*80)\n",
    "print(\"⚠️  This is the FIRST and ONLY time holdout data is used!\\n\")\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"fusion_model_best_FIXED.pth\"))\n",
    "holdout_loss, holdout_f1, holdout_acc = evaluate(model, holdout_loader)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best Validation F1: {best_f1:.4f}\")\n",
    "print(f\"Holdout Test F1:    {holdout_f1:.4f}\")\n",
    "print(f\"Holdout Test Acc:   {holdout_acc:.4f}\")\n",
    "print(f\"Difference:         {holdout_f1 - best_f1:+.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Log final results to WandB\n",
    "wandb.log({\n",
    "    \"final/best_val_f1\": best_f1,\n",
    "    \"final/holdout_f1\": holdout_f1,\n",
    "    \"final/holdout_acc\": holdout_acc\n",
    "})\n",
    "\n",
    "# Get detailed predictions for classification report\n",
    "model.eval()\n",
    "all_preds, all_targets = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in holdout_loader:\n",
    "        pixel_values = batch['pixel_values'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        outputs = model(pixel_values, input_ids, mask)\n",
    "        all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "        all_targets.extend(labels.numpy())\n",
    "\n",
    "print(\"\\nClassification Report (Holdout):\")\n",
    "print(classification_report(all_targets, all_preds, digits=4, zero_division=0))\n",
    "\n",
    "wandb.finish()\n",
    "print(\"\\n✅ Training and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 12. Save to Google Drive (Optional)\n",
    "from google.colab import drive\n",
    "import shutil\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "target_dir = \"/content/drive/MyDrive/Rakuten_models\"\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "target_file = os.path.join(target_dir, f\"fusion_swin_deberta_FIXED_{timestamp}.pth\")\n",
    "shutil.copy(\"fusion_model_best_FIXED.pth\", target_file)\n",
    "print(f\"✓ Model saved to: {target_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}